{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaifEleslamElgalaly/food-101-classification/blob/main/Another_copy_of_Visualization_Tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and Preprocessing Dataset"
      ],
      "metadata": {
        "id": "GDYZ0_31g1pk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lB64HRcwRqd"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive and copy dataset if needed\n",
        "from google.colab import drive\n",
        "import os, shutil, stat, collections\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp -r \"/content/drive/MyDrive/food-101\" \"/content/\"\n",
        "data_path = \"/content/food-101\""
      ],
      "metadata": {
        "id": "5fUEhTM9yloX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) استيراد المكتبات\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "G7JMOMzS7Ksr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) تجهيز التوازي (multiprocessing)\n",
        "num_processes = 6\n",
        "pool = mp.Pool(processes=num_processes)"
      ],
      "metadata": {
        "id": "g2j0EAzX7TlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) بناء خريطة الكلاسات\n",
        "class_to_ix, ix_to_class = {}, {}\n",
        "with open(os.path.join(data_path, 'meta', 'classes.txt'), 'r') as f:\n",
        "    classes = [l.strip() for l in f]\n",
        "    class_to_ix = {c:i for i,c in enumerate(classes)}\n",
        "    ix_to_class = {i:c for i,c in enumerate(classes)}\n",
        "sorted_class_to_ix = collections.OrderedDict(sorted(class_to_ix.items()))\n"
      ],
      "metadata": {
        "id": "pHL3e99Z7-z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) تقسيم الصور إلى مجلدات train / test (مرة واحدة)\n",
        "def generate_dir_file_map(path_txt):\n",
        "    d = defaultdict(list)\n",
        "    with open(path_txt) as f:\n",
        "        for line in f:\n",
        "            dir_name, fname = line.strip().split('/')\n",
        "            d[dir_name].append(fname + '.jpg')\n",
        "    return d\n",
        "\n",
        "train_map = generate_dir_file_map(os.path.join(data_path, 'meta', 'train.txt'))\n",
        "test_map  = generate_dir_file_map(os.path.join(data_path, 'meta', 'test.txt'))\n",
        "\n",
        "def copytree(src, dst, ignore_map):\n",
        "    if not os.path.exists(dst):\n",
        "        os.makedirs(dst)\n",
        "    for class_name in os.listdir(src):\n",
        "        sdir = os.path.join(src, class_name)\n",
        "        ddir = os.path.join(dst, class_name)\n",
        "        os.makedirs(ddir, exist_ok=True)\n",
        "        for img_name in os.listdir(sdir):\n",
        "            keep = img_name in ignore_map[class_name]\n",
        "            if keep:\n",
        "                shutil.copy(os.path.join(sdir, img_name), os.path.join(ddir, img_name))\n",
        "\n",
        "if not os.path.isdir(os.path.join(data_path, 'train')):\n",
        "    copytree(os.path.join(data_path, 'images'), os.path.join(data_path, 'train'), train_map)\n",
        "if not os.path.isdir(os.path.join(data_path, 'test')):\n",
        "    copytree(os.path.join(data_path, 'images'), os.path.join(data_path, 'test'), test_map)\n"
      ],
      "metadata": {
        "id": "vjM7YL3x8CaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data Augmentation للـ Train\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Validation/Test ما نعمللهمش Augmentation بس نعمل Rescale\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# توليد الداتا أثناء التدريب\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(data_path, 'train'),\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(data_path, 'test'),\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "cjsRqugC8Nk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization Tools"
      ],
      "metadata": {
        "id": "fCA-COo9g_X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets"
      ],
      "metadata": {
        "id": "8qZ2bCv9PbVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "from ipywidgets import interact # Import interact from ipywidgets\n",
        "\n",
        "\n",
        "\n",
        "@interact(n_class=sorted_class_to_ix)\n",
        "def show_random_images_of_class(n_class=0):\n",
        "    class_name = ix_to_class[n_class]\n",
        "    folder_path = os.path.join(data_path, 'train', class_name)  # للتدريب\n",
        "\n",
        "    all_images = os.listdir(folder_path)\n",
        "    chosen_images = random.sample(all_images, min(len(all_images), 32))\n",
        "\n",
        "    nrows, ncols = 4, 8\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 8))\n",
        "    fig.suptitle(f\"Class: {class_name}\", fontsize=16)\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < len(chosen_images):\n",
        "            img_path = os.path.join(folder_path, chosen_images[i])\n",
        "            img = Image.open(img_path)\n",
        "            ax.imshow(img)\n",
        "        ax.set_axis_off()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bqDCJ8QIPdjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@interact(n_class=sorted_class_to_ix)\n",
        "def show_random_images_of_class(n_class=0):\n",
        "    class_name = ix_to_class[n_class]\n",
        "    folder_path = os.path.join(data_path, 'test', class_name)\n",
        "\n",
        "    all_images = os.listdir(folder_path)\n",
        "    chosen_images = random.sample(all_images, min(len(all_images), 32))\n",
        "\n",
        "    nrows, ncols = 4, 8\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 8))\n",
        "    fig.suptitle(f\"Class: {class_name}\", fontsize=16)\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < len(chosen_images):\n",
        "            img_path = os.path.join(folder_path, chosen_images[i])\n",
        "            img = Image.open(img_path)\n",
        "            ax.imshow(img)\n",
        "        ax.set_axis_off()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Op29Tu0HjolR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Augmentation"
      ],
      "metadata": {
        "id": "yevM0vgm80ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "# عدد الكلاسات\n",
        "n_classes = len(sorted_class_to_ix)\n",
        "\n",
        "# إعداد الـ train_datagen مع Augmentations\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# إعداد الـ validation/test datagen (بدون augmentations)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# إعداد الـ Generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(data_path, 'train'),\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(data_path, 'test'),\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "7RP-TJ9jlBJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# عرض صور من الـ train_generator مع Augmentation\n",
        "def plot_augmented_images(generator):\n",
        "    x_batch, y_batch = next(generator)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i in range(9):\n",
        "        plt.subplot(3,3,i+1)\n",
        "        plt.imshow(x_batch[i])\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "plot_augmented_images(train_generator)\n"
      ],
      "metadata": {
        "id": "DKK-oI3MlGPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "3Hza3EDX-XCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, AveragePooling2D, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import os\n"
      ],
      "metadata": {
        "id": "IhsJ24VC9DiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# تأكد إنك بتستخدم كرت شاشة لو متاح\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "tCTM3R1kUqwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear Session\n",
        "tf.keras.backend.clear_session()\n"
      ],
      "metadata": {
        "id": "NKByjz9wUvTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تحميل InceptionV3 بدون الطبقة الأخيرة\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=Input(shape=(299, 299, 3)))\n",
        "\n",
        "# بناء الطبقات الجديدة\n",
        "x = base_model.output\n",
        "x = AveragePooling2D(pool_size=(8,8))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Flatten()(x)\n",
        "predictions = Dense(\n",
        "    n_classes,\n",
        "    activation='softmax',\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    kernel_regularizer=l2(0.0005)\n",
        ")(x)"
      ],
      "metadata": {
        "id": "eVge6lRSWTMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# بناء الموديل النهائي\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# إعداد الـ Optimizer\n",
        "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "checkpoint_cb = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', verbose=1)\n",
        "csv_logger_cb = CSVLogger('training_log.csv')\n",
        "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "def schedule(epoch):\n",
        "    if epoch < 15:\n",
        "        return 0.01\n",
        "    elif epoch < 28:\n",
        "        return 0.002\n",
        "    else:\n",
        "        return 0.0004\n",
        "\n",
        "lr_scheduler_cb = LearningRateScheduler(schedule)\n",
        "\n",
        "# التدريب\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=32,\n",
        "    verbose=1,\n",
        "    callbacks=[lr_scheduler_cb, csv_logger_cb, checkpoint_cb, early_stopping_cb]\n",
        ")"
      ],
      "metadata": {
        "id": "mYAkIWsfWXtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8F8TvkTZWkhw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}